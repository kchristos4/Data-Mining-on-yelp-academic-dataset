{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "0ccd4294",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import scipy as sp\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "256c00a0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "business_id\n",
      "-AbzJTLQdbdQrhRzQLgsKA    Kingyo has summer appetizer specials for $3.00...\n",
      "-HxLFWKVgXSU8JlR21PBkg    \"Carluccio's: Way Delish\"\\n\\nEver find yoursel...\n",
      "-LmhsdQproqCf5EQoD06rQ    Down in south Philly for a meeting at my daugh...\n",
      "-MkngKKkTIVfnUbq2S1ucQ    Dee-frickin'-licious thick crust pizza!!! I or...\n",
      "-PMXnNJ1D67NkAupRHNkpQ    I've always preferred domino's over pizza hut!...\n",
      "                                                ...                        \n",
      "zUJMvjK6aBeQtVCowZ85-w    Excelent! Food is wondeful, hot, and fresh! Th...\n",
      "zeounyPVXFZEz1c9KtptLA    Pizza, wings, steaks are good.. chicken finger...\n",
      "zgX8sYCRGVJ9M5LETpJ60A    I popped in there one afternoon to pick up som...\n",
      "zqisPpgCURrgLf4TVnI8RQ    This review is for poke bowl. Very fresh salad...\n",
      "zzyx5x0Z7xXWWvWnZFuxlQ    Maybe the pizza is good here... but I can real...\n",
      "Name: text, Length: 951, dtype: object\n",
      "finished\n"
     ]
    }
   ],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.cluster import KMeans\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.cluster import AgglomerativeClustering\n",
    "from sklearn.metrics import silhouette_score\n",
    "\n",
    "\n",
    "\n",
    "df_businesses = pd.read_csv('philly_restaurants_categories.csv')\n",
    "\n",
    "\n",
    "\n",
    "chunks = pd.read_json('yelp_academic_dataset_review.json', lines=True,chunksize=100000)\n",
    "df_reviews = pd.DataFrame()\n",
    "\n",
    "for chunk in chunks:\n",
    "    temp = chunk[chunk['business_id'].isin(df_businesses['business_id'])]\n",
    "    df_reviews = pd.concat([df_reviews,temp])\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "merged_reviews = df_reviews[['business_id','text']].groupby('business_id').agg({'text': ' '.join})\n",
    "print(merged_reviews['text'])\n",
    "\n",
    "\n",
    "\n",
    "print(\"finished\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "9717a84d",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Mainframe\\AppData\\Local\\Temp\\ipykernel_6904\\1970712223.py:10: FutureWarning: The default value of regex will change from True to False in a future version.\n",
      "  merged_reviews[\"text\"] = merged_reviews[\"text\"].str.replace(\"[^a-zA-Z]\", \" \")\n",
      "C:\\Users\\Mainframe\\anaconda3\\lib\\site-packages\\sklearn\\neighbors\\_classification.py:228: FutureWarning: Unlike other reduction functions (e.g. `skew`, `kurtosis`), the default behavior of `mode` typically preserves the axis it acts along. In SciPy 1.11.0, this behavior will change: the default value of `keepdims` will become False, the `axis` over which the statistic is taken will be eliminated, and the value None will no longer be accepted. Set `keepdims` to True or False to avoid this warning.\n",
      "  mode, _ = stats.mode(_y[neigh_ind, k], axis=1)\n",
      "C:\\Users\\Mainframe\\anaconda3\\lib\\site-packages\\sklearn\\neighbors\\_classification.py:228: FutureWarning: Unlike other reduction functions (e.g. `skew`, `kurtosis`), the default behavior of `mode` typically preserves the axis it acts along. In SciPy 1.11.0, this behavior will change: the default value of `keepdims` will become False, the `axis` over which the statistic is taken will be eliminated, and the value None will no longer be accepted. Set `keepdims` to True or False to avoid this warning.\n",
      "  mode, _ = stats.mode(_y[neigh_ind, k], axis=1)\n",
      "C:\\Users\\Mainframe\\anaconda3\\lib\\site-packages\\sklearn\\neighbors\\_classification.py:228: FutureWarning: Unlike other reduction functions (e.g. `skew`, `kurtosis`), the default behavior of `mode` typically preserves the axis it acts along. In SciPy 1.11.0, this behavior will change: the default value of `keepdims` will become False, the `axis` over which the statistic is taken will be eliminated, and the value None will no longer be accepted. Set `keepdims` to True or False to avoid this warning.\n",
      "  mode, _ = stats.mode(_y[neigh_ind, k], axis=1)\n",
      "C:\\Users\\Mainframe\\anaconda3\\lib\\site-packages\\sklearn\\neighbors\\_classification.py:228: FutureWarning: Unlike other reduction functions (e.g. `skew`, `kurtosis`), the default behavior of `mode` typically preserves the axis it acts along. In SciPy 1.11.0, this behavior will change: the default value of `keepdims` will become False, the `axis` over which the statistic is taken will be eliminated, and the value None will no longer be accepted. Set `keepdims` to True or False to avoid this warning.\n",
      "  mode, _ = stats.mode(_y[neigh_ind, k], axis=1)\n",
      "C:\\Users\\Mainframe\\anaconda3\\lib\\site-packages\\sklearn\\neighbors\\_classification.py:228: FutureWarning: Unlike other reduction functions (e.g. `skew`, `kurtosis`), the default behavior of `mode` typically preserves the axis it acts along. In SciPy 1.11.0, this behavior will change: the default value of `keepdims` will become False, the `axis` over which the statistic is taken will be eliminated, and the value None will no longer be accepted. Set `keepdims` to True or False to avoid this warning.\n",
      "  mode, _ = stats.mode(_y[neigh_ind, k], axis=1)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score\n",
    "from sklearn.model_selection import KFold\n",
    "\n",
    "\n",
    "merged_reviews[\"text\"] = merged_reviews[\"text\"].str.lower()\n",
    "merged_reviews[\"text\"] = merged_reviews[\"text\"].str.replace(\"[^a-zA-Z]\", \" \")\n",
    "\n",
    "kf = KFold(n_splits=5, shuffle=True, random_state=0)\n",
    "\n",
    "log_reg = LogisticRegression()\n",
    "svm = SVC()\n",
    "knn = KNeighborsClassifier()\n",
    "\n",
    "accuracies = []\n",
    "precisions = []\n",
    "recalls = []\n",
    "f1_scores = []\n",
    "conf_matrices = []\n",
    "\n",
    "for train_index, test_index in kf.split(merged_reviews):\n",
    "    \n",
    "    train_data = merged_reviews.iloc[train_index]\n",
    "    test_data = merged_reviews.iloc[test_index]\n",
    "    \n",
    "\n",
    "    vectorizer = TfidfVectorizer(stop_words='english',max_df=0.6,max_features=1000)\n",
    "    x_train = vectorizer.fit_transform(train_data['text'])\n",
    "    y_train = train_data[\"text\"]\n",
    "\n",
    "    x_test = vectorizer.transform(test_data[\"text\"])\n",
    "    y_test = test_data[\"text\"]\n",
    "\n",
    "\n",
    "\n",
    "    #Logistic Regression\n",
    "    log_reg.fit(x_train, y_train)\n",
    "    y_pred = log_reg.predict(x_test)\n",
    "    acc = accuracy_score(y_test, y_pred)\n",
    "    prec = precision_score(y_test, y_pred,average='micro')\n",
    "    rec = recall_score(y_test, y_pred,average='micro')\n",
    "    f1 = f1_score(y_test, y_pred,average='micro')\n",
    "    conf = confusion_matrix(y_test,y_pred)\n",
    "    \n",
    "    accuracies.append(acc)\n",
    "    precisions.append(prec)\n",
    "    recalls.append(rec)\n",
    "    f1_scores.append(f1)\n",
    "    conf_matrices.append(conf)\n",
    "\n",
    "\n",
    "    #SVM\n",
    "    svm.fit(x_train, y_train)\n",
    "    y_pred = svm.predict(x_test)\n",
    "    acc = accuracy_score(y_test, y_pred)\n",
    "    prec = precision_score(y_test, y_pred,average='micro')\n",
    "    rec = recall_score(y_test, y_pred,average='micro')\n",
    "    f1 = f1_score(y_test, y_pred,average='micro')\n",
    "    conf = confusion_matrix(y_test,y_pred)\n",
    "    \n",
    "    accuracies.append(acc)\n",
    "    precisions.append(prec)\n",
    "    recalls.append(rec)\n",
    "    f1_scores.append(f1)\n",
    "    conf_matrices.append(conf)\n",
    "\n",
    "\n",
    "\n",
    "    #KNN\n",
    "    knn.fit(x_train, y_train)\n",
    "    y_pred = knn.predict(x_test)\n",
    "    acc = accuracy_score(y_test, y_pred)\n",
    "    prec = precision_score(y_test, y_pred,average='micro')\n",
    "    rec = recall_score(y_test, y_pred,average='micro')\n",
    "    f1 = f1_score(y_test, y_pred,average='micro')\n",
    "    conf = confusion_matrix(y_test,y_pred)\n",
    "\n",
    "    accuracies.append(acc)\n",
    "    precisions.append(prec)\n",
    "    recalls.append(rec)\n",
    "    f1_scores.append(f1)\n",
    "    conf_matrices.append(conf)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "cd41c4a6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "329\n",
      "321\n",
      "297\n",
      "330\n",
      "330\n",
      "291\n",
      "329\n",
      "330\n",
      "305\n",
      "330\n",
      "323\n",
      "291\n",
      "334\n",
      "327\n",
      "299\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Mainframe\\AppData\\Local\\Temp\\ipykernel_6904\\1754833075.py:15: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.\n",
      "  conf_matrices1 = np.array(conf_matrices).reshape(-1,3)\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "operands could not be broadcast together with shapes (329,329) (330,330) ",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp\\ipykernel_6904\\1754833075.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     19\u001b[0m \u001b[0mavg_recalls\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmean\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mrecalls1\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     20\u001b[0m \u001b[0mavg_f1_scores\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmean\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mf1_scores1\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 21\u001b[1;33m \u001b[0mavg_conf_matrices\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmean\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mconf_matrices1\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     22\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     23\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<__array_function__ internals>\u001b[0m in \u001b[0;36mmean\u001b[1;34m(*args, **kwargs)\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\numpy\\core\\fromnumeric.py\u001b[0m in \u001b[0;36mmean\u001b[1;34m(a, axis, dtype, out, keepdims, where)\u001b[0m\n\u001b[0;32m   3438\u001b[0m             \u001b[1;32mreturn\u001b[0m \u001b[0mmean\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0maxis\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0maxis\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mdtype\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mout\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mout\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   3439\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 3440\u001b[1;33m     return _methods._mean(a, axis=axis, dtype=dtype,\n\u001b[0m\u001b[0;32m   3441\u001b[0m                           out=out, **kwargs)\n\u001b[0;32m   3442\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\numpy\\core\\_methods.py\u001b[0m in \u001b[0;36m_mean\u001b[1;34m(a, axis, dtype, out, keepdims, where)\u001b[0m\n\u001b[0;32m    177\u001b[0m             \u001b[0mis_float16_result\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mTrue\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    178\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 179\u001b[1;33m     \u001b[0mret\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mumr_sum\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0marr\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mout\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkeepdims\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mwhere\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mwhere\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    180\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mret\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmu\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mndarray\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    181\u001b[0m         ret = um.true_divide(\n",
      "\u001b[1;31mValueError\u001b[0m: operands could not be broadcast together with shapes (329,329) (330,330) "
     ]
    }
   ],
   "source": [
    "'''for i in range(15):\n",
    "    print(i)\n",
    "    print(\"Accuracies: \",accuracies[i])\n",
    "    print(\"Precisions: \",precisions[i])\n",
    "    print(\"recalls: \",recalls[i])\n",
    "    print(\"f1: \",f1_scores[i])\n",
    "    print(\"conf: \",conf_matrices[i])\n",
    "'''\n",
    "accuracies1 = np.array(accuracies).reshape(-1, 3)\n",
    "precisions1 = np.array(precisions).reshape(-1, 3)\n",
    "recalls1 = np.array(recalls).reshape(-1, 3)\n",
    "f1_scores1 = np.array(f1_scores).reshape(-1, 3)\n",
    "for i in range(len(conf_matrices)):\n",
    "    print(len(conf_matrices[i]))\n",
    "conf_matrices1 = np.array(conf_matrices).reshape(-1,3)\n",
    "\n",
    "avg_accuracies = np.mean(accuracies1, axis=0)\n",
    "avg_precisions = np.mean(precisions1, axis=0)\n",
    "avg_recalls = np.mean(recalls1, axis=0)\n",
    "avg_f1_scores = np.mean(f1_scores1, axis=0)\n",
    "avg_conf_matrices = np.mean(conf_matrices1, axis=0)\n",
    "\n",
    "\n",
    "print(\"avg accuracy: \", avg_accuracies)\n",
    "print(\"avg precision: \", avg_precisions)\n",
    "print(\"avg recall: \", avg_recalls)\n",
    "print(\"avg f1-Score: \", avg_f1_scores)\n",
    "print(\"avg confusion matrix: \", avg_conf_matrices)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  },
  "vscode": {
   "interpreter": {
    "hash": "35b4ab4068d51c50da5b0c42f38812a329770a0d24d47970619c7521cf6a8da8"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
